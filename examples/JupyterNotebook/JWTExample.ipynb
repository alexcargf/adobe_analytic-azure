{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4dd5cd33-e410-4a2d-9ffd-1f00a32ec5a1","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#imports\n","from azure.storage.blob import BlobClient \n","import os\n","from datetime import datetime\n","from pytz import timezone\n","import webbrowser\n","from urllib.parse import urlparse\n","from urllib.parse import parse_qs\n","from urllib.parse import urlencode\n","from datetime import datetime\n","from datetime import timedelta\n","import time\n","import json\n","import jwt\n","import os\n","import requests\n","import pandas as pd\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cc48edf1-a41b-49d5-aae9-f8ac27e7e3fa","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# dbutils.widgets.removeAll()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"70d7951d-94b2-4795-8f33-53fc8e69389c","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#get pipeline parameters\n","dbutils.widgets.text(\"segments\", \"\", \"\")\n","segments = dbutils.widgets.get(\"segments\")\n","\n","dbutils.widgets.text(\"dimensions\", \"\", \"\")\n","dimensions = dbutils.widgets.get(\"dimensions\")\n","\n","dbutils.widgets.text(\"metrics\", \"\", \"\")\n","metrics = dbutils.widgets.get(\"metrics\")\n","\n","dbutils.widgets.text(\"output_file_path\", \"\", \"\")\n","output_file_path = dbutils.widgets.get(\"output_file_path\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b5ab6c75-b572-461a-9b0e-29489d1fa557","showTitle":false,"title":""}},"outputs":[],"source":["#get secrets\n","ADOBE_ORG_ID = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-org-id\")\n","SUBJECT_ACCOUNT = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-subject-account\")\n","CLIENT_ID = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-client-id\")\n","CLIENT_SECRET = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-client-secret\")\n","GLOBAL_COMPANY_ID = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-global-company-id\")\n","REPORT_SUITE_ID = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-report-suite-id\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"35b3c987-d2c7-42ce-b848-bd8b17aa4cc4","showTitle":false,"title":""}},"outputs":[],"source":["class analytics_client:\n","\n","    def __init__(self, adobe_org_id = None, subject_account = None, client_id = None, auth_client_id = None, client_secret = None, account_id = None, debugging = False):\n","        '''\n","        Adobe Analytics Reports API client.\n","\n","        An Adobe Analytics client is created that initiates the authentication process,\n","        handles the JWT token that is needed to perform the requests and\n","        constracts the request JSON object. The JSON object is send as an argument to the reporting API.\n","        \n","        Parameters\n","        ----------\n","        adobe_org_id : string\n","            Adobe Organisation ID\n","\n","        subject_account : string\n","            Technical account ID\n","\n","        client_id : string\n","            Client ID\n","\n","        auth_client_id : string\n","            OAuth2 Client ID\n","\n","        client_secret : string\n","            Client Secret\n","\n","        account_id : string\n","            Account ID (Global Company ID)\n","\n","        Returns\n","        -------\n","        Instance of analytics_client\n","        '''\n","\n","\n","        self.adobe_auth_host = 'https://ims-na1.adobelogin.com'\n","        self.adobe_auth_url = '/'.join([self.adobe_auth_host, 'ims/exchange/jwt'])\n","        self.adobe_org_id = adobe_org_id\n","        self.subject_account = subject_account\n","\n","        self.client_id = client_id\n","        self.client_secret = client_secret\n","        \n","        self.account_id = account_id\n","\n","        self.auth_client_id = auth_client_id\n","        self.redirect_uri = 'https://www.adobe.com'\n","        self.adobe_auth_login_url = '{}/ims/token/v1'.format(self.adobe_auth_host)\n","\n","        self.experience_cloud_metascope = 'https://ims-na1.adobelogin.com/s/ent_analytics_bulk_ingest_sdk'\n","\n","        self.analytics_url = \"https://analytics.adobe.io/api/{}/reports\".format(self.account_id)\n","\n","        self.report_object = self._generate_empty_report_object()\n","        self.dimensions = []\n","        self.debugging = debugging\n","\n","    def _read_private_key(self):\n","        # Request private Key\n","        # This secret scope is backed by Azure Key vault\n","        aa_private_key = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"aa-private-key\")\n","        private_key = bytes('-----BEGIN PRIVATE KEY-----\\n'+aa_private_key+'\\n-----END PRIVATE KEY-----', 'utf-8')\n","        return private_key\n","\n","    def _get_jwtPayload(self, expiration = None ):\n","\n","        if expiration is None:\n","            expiration = datetime.utcnow()\n","\n","        jwtPayloadJson = {}\n","        jwtPayloadJson['iss'] = self.adobe_org_id\n","        jwtPayloadJson['sub'] = self.subject_account\n","        jwtPayloadJson[self.experience_cloud_metascope] = True\n","        jwtPayloadJson['aud'] = '/'.join([self.adobe_auth_host, 'c', self.client_id])\n","        jwtPayloadJson[\"exp\"] = expiration + timedelta(minutes=30)\n","\n","        return jwtPayloadJson\n","\n","    def _renew_access_token(self):\n","\n","        private_key = self._read_private_key()\n","\n","        jwtPayloadJson = self._get_jwtPayload()\n","        # Encode the jwt Token\n","        jwttoken = jwt.encode(jwtPayloadJson, private_key, algorithm='RS256')\n","\n","        accessTokenRequestPayload = {\n","            'client_id': self.client_id,\n","            'client_secret': self.client_secret, \n","            'jwt_token': jwttoken\n","        }\n","        result = requests.post(self.adobe_auth_url,\n","                               data=accessTokenRequestPayload)\n","        resultjson = json.loads(result.text)\n","\n","        if (result.status_code != 200):\n","            raise ValueError('Response code error', result.status_code)\n","\n","        return resultjson['access_token']\n","\n","    def _request_oauth_authorisation_code(self):\n","        url = '{}/ims/authorize?client_id={}&redirect_uri={}&scope=openid,AdobeID,read_organizations,additional_info.job_function,additional_info.projectedProductContext&response_type=code'.format(self.adobe_auth_host, self.auth_client_id, self.redirect_uri)\n","        webbrowser.open(url)\n","\n","    def _obtain_oauth_code(self):\n","        self._request_oauth_authorisation_code()\n","        input_text = 'Paste the Adobe login URL that includes the Auth Code (starting with \"eyJ...\")'\n","        print(input_text)\n","        url_text = input()\n","        \n","        url_object = urlparse(url_text)\n","        auth_code = parse_qs(url_object.query)['code'][0]\n","        return auth_code\n","\n","    def _obtain_oauth_access_token(self):\n","        payload_data = {\n","            'grant_type' : 'authorization_code',\n","            'client_id' : self.auth_client_id,\n","            'client_secret' : self.client_secret,\n","            'code' : self._obtain_oauth_code()\n","        }\n","        res = requests.request(\"POST\", url = self.adobe_auth_login_url , data = payload_data)\n","        \n","        if (res.status_code != 200):\n","            raise ValueError('Response code error', res.status_code)\n","\n","        return res.json()['access_token']\n","\n","    def _get_request_headers(self):\n","\n","        if (self.auth_client_id and not self.access_token):\n","            self.access_token = self._obtain_oauth_access_token()\n","        elif self.client_id:\n","            self.access_token = self._renew_access_token()\n","\n","        analytics_header = {\n","            \"X-Api-Key\": (self.client_id or self.auth_client_id),\n","            \"x-proxy-global-company-id\": self.account_id,\n","            \"Authorization\": \"Bearer \" + self.access_token,\n","            \"Accept\": \"application/json\",\n","            \"Content-Type\": \"application/json\"\n","        }\n","\n","        return analytics_header\n","\n","    def _authenticate(self):\n","        self.access_token = self._obtain_oauth_access_token()\n","\n","    @staticmethod\n","    def _generate_empty_report_object():\n","        report = {\n","            \"rsid\": \"\",\n","            \"globalFilters\": [],\n","            \"metricContainer\": {\n","                \"metrics\": []\n","            },\n","            \"dimension\": \"\"\n","        }\n","        return report\n","\n","    @staticmethod\n","    def _generate_metric_structure():\n","        metric = {\n","            \"columnId\": \"\",\n","            \"id\": \"\"\n","        }\n","        return metric\n","\n","    @staticmethod\n","    def _format_date_range(date_start, date_end, hour_start, hour_end):\n","        '''\n","        Format start and ending date.\n","\n","        The starting date and the ending date for the reporting period are formated in an API-compatible format.\n","        The final value is saved in the JSON report object.\n","        Note: The end-date provided is inclusive. For that reason it is converted to the start of the next day. \n","\n","        Example: If the report needs to end on 1st of March 2020, then the value is convered into 2020-03-02T00:00:00.000\n","\n","        The hours are being added on top of the existing day. Examples:\n","        - If the starting date is 26/11/2020 and starting hour is 13, then the starting time point will be 2020-11-26T13:00:00.000 \n","        - (!) If the ending date is 29/11/2020 and ending hour is 17, then the ending time point will be 2020-11-29T17:00:00.000 \n","        - (!) If the ending date is 29/11/2020 and ending hour is 0, then the ending time point will be 2020-11-30T00:00:00.000 \n","\n","        Note: If the ending hour is <> 0, then the full day is captured. Otherwise it captures only the portion of the day.\n","\n","        Parameters\n","        ----------\n","        date_start : string\n","            Reporting period start date. Format: YYYY-MM-DD i.e. 2017-12-31. The value is converted to 2017-12-31T00:00:00.000\n","\n","        date_end : string\n","            Reporting period start date. Format: YYYY-MM-DD i.e. 2018-01-31. The value is converted to 2018-02-01T00:00:00.000\n","\n","        hour_start: int\n","            Reporting period start hour. Integer value from 0 to 24\n","\n","        hour_end: int\n","            Reporting period start hour. Integer value from 0 to 24\n","\n","        Returns\n","        -------\n","        string\n","            The final formated value i.e. 2017-12-31T00:00:00.000/2018-02-01T00:00:00.000        \n","        '''\n","        date_start = datetime.strptime(date_start, '%Y-%m-%d')\n","        date_start = date_start + timedelta(hours = hour_start, microseconds=1)\n","        date_start = date_start.isoformat('T')\n","\n","        date_end = datetime.strptime(date_end, '%Y-%m-%d')\n","        \n","        if hour_end == 0:\n","            hour_end = 24\n","        date_end = date_end + timedelta(hours = hour_end, minutes=00, seconds=00, milliseconds=999)\n","        date_end = date_end.isoformat('T')\n","        final_date = '{}/{}'.format(date_start[:-7], date_end[:-7])\n","        return final_date\n","\n","    def set_report_suite(self, report_suite_id):\n","        '''\n","        Set Adobe Analytics report suite.\n","\n","        The report suite from which the data needs to be downloaded from.\n","\n","        Parameters\n","        ----------\n","        report_suite_id : object - optional\n","            Report suite ID.\n","        '''\n","\n","        self.report_object['rsid'] = report_suite_id\n","\n","    def _get_page(self, report_object = None):\n","        '''\n","        Perform report request.\n","\n","        A post request to the API endpoint is performed based on the report object. Either the main report object\n","        is used or a customised object can be passed as an argument.\n","\n","        Parameters\n","        ----------\n","        report_object : object - optional\n","            Report object as specified in https://github.com/AdobeDocs/analytics-2.0-apis/blob/master/reporting-guide.md\n","\n","        Returns\n","        -------\n","        response object\n","            Response object as returned from the post request performed.\n","        '''\n","        if report_object is None:\n","            report_object = self.report_object\n","\n","        analytics_header = self._get_request_headers()\n","        \n","        status_code = None\n","        time_delay = 1\n","        while status_code != 200:\n","            \n","            page = requests.post(\n","                self.analytics_url,\n","                headers=analytics_header,\n","                data=json.dumps(report_object),\n","                timeout = 360\n","            )\n","            if (self.debugging):\n","                self.write_log('request_object', json.dumps(report_object))\n","                self.write_log('response', page.text)\n","                \n","            if (page.status_code == 429):\n","                # Response code 429\n","                # {\"error_code\":\"429050\",\"message\":\"Too many requests\"}\n","                print('Response code error: {}'.format(page.status_code))\n","                \n","            elif (page.status_code != 200):\n","                page.raise_for_status()\n","                # raise ValueError('Response code error', page.status_code)\n","\n","            status_code = page.status_code  \n","            time.sleep(time_delay)\n","            time_delay = time_delay * 2\n","\n","        return page\n","\n","    def get_report(self, custom_report_object = None):\n","        self._set_page_number(0)\n","        # Get initial page\n","        data = self._get_page(custom_report_object)\n","        self.logger(data.text)\n","        json_obj = json.loads(data.text)\n","        total_pages = json_obj['totalPages']\n","        current_page = 1\n","        is_last_page = False\n","        df_data = self.format_output(data)\n","\n","        # Download additional data if more than 1 pages are available\n","        while (total_pages > 1 and not is_last_page):\n","            \n","            if (custom_report_object is not None):\n","                # Workaround - This is done because in multiple breakdowns, pagination does not work in sub-breakdowns.\n","                custom_report_object['settings']['page'] = '{}'.format(current_page)\n","            \n","            self.logger('Parsing page {}'.format(current_page)) \n","            self._set_page_number(current_page)\n","            data = self._get_page(custom_report_object)\n","            self.logger(data.text)\n","            json_obj = json.loads(data.text)\n","            is_last_page = json_obj['lastPage']\n","            current_page = current_page + 1\n","            df_current_page = self.format_output(data)\n","\n","            df_data = df_data.append(df_current_page, ignore_index=True)\n","\n","        return df_data\n","\n","    def get_report_multiple_breakdowns(self):\n","        '''\n","        Download report that contains multiple dimensions.\n","\n","        Initial report (top-level dimension) is downloaded using get_report() method. Subsequent dimensions\n","        are downloaded using get_report_breakdown(). This is because sub-breakdowns rely on itemId.\n","\n","        Per remaining (non-top) dimensions, get_report_breakdown() is invoked.\n","\n","        Returns\n","        -------\n","        Pandas data frame object\n","            Data frame with columns:\n","            - itemId_lvl_*      : ID of the value per breakdown level\n","            - value_lvl_*       : The row value for the particular breakdown combination\n","            - metrics/{metric}  : Metric name is added in the API request i.e. metrics/visits\n","        '''\n","        \n","        current_dimensions = []\n","        # Download 1st level data\n","        df_page = self.get_report()\n","        level = 1\n","\n","        dim_index = 1\n","        remaining_dimensions = list(self.dimensions)\n","        remaining_dimensions.pop(0)\n","\n","        # Re-format column names\n","        if (len(remaining_dimensions) > 0):\n","            df_page = df_page.filter(regex='^itemId|^value', axis = 'columns')\n","        \n","        df_page = df_page.rename(\n","                columns = {\n","                    'itemId' : 'itemId_lvl_{}'.format(level),\n","                    'value' : 'value_lvl_{}'.format(level)}\n","                )    \n","        \n","        for breakdown in remaining_dimensions:\n","            level = level + 1\n","            dim_index = dim_index + 1\n","            current_dimensions.append(breakdown)\n","            \n","            results_broken_down = df_page.apply(self.get_report_breakdown, axis = 1 , dimensions = current_dimensions, current_level = level)\n","            dl = []\n","            for i in results_broken_down:\n","                dl.append(i)\n","            \n","            results_broken_down = pd.concat(dl, ignore_index=True)\n","\n","            df_page = df_page.filter(regex='^itemId|^value', axis = 'columns')\n","            df_page = pd.merge(df_page, results_broken_down, how = 'right')\n","            \n","        return df_page\n","\n","    def get_report_breakdown(self, df_page, dimensions, current_level = None):\n","        '''\n","        Download broken-down dimensions of a single report.\n","\n","        For the existing dimensions in a data frame, iterate through all entries, generate a new report JSON object and\n","        download the new row values and metrics. \n","        \n","        This function is invoked multiple times based on the number of dimensions. \n","        Invoked once per dimension level. i.e. if 3 dimensions are added in the initalisation, it will be invoked twice; \n","        once for the 2nd level and once for the 3rd level dimension. \n","\n","        Parameters\n","        ----------\n","        df_page : Pandas data frame\n","            Contains a previously downloaded report\n","\n","        dimensions : array\n","            Array of dimensions that have already been requested before and data has been downloaded. This assists in constructing the new \n","            JSON request object and apply the correct global filters\n","\n","        current_level : str - optional\n","            The depth in the dimension tree. Populated only from level 2 and upwards\n","\n","        Returns\n","        -------\n","        response object\n","            Response object as returned from the post request performed.\n","        '''\n","\n","        self.logger('Downloading additional breakdown')\n","        self.logger(dimensions)\n","        \n","        tmp_report_object = self.report_object\n","        \n","        item_ids = df_page.filter(regex='^itemId').array\n","        \n","        for idx in range(len(dimensions)):\n","            dimension = dimensions[idx]\n","            parent_itemId = item_ids[idx]\n","            self.logger('Dimension {}, Item ID: {}'.format(dimension,parent_itemId))\n","            tmp_report_object = self._add_breakdown_report_object(tmp_report_object, dimension, parent_itemId)\n","\n","        results = self.get_report(custom_report_object=tmp_report_object)\n","        # The itemId in the results is set to minus 1 to match with the parent ID during the merge\n","        for key in df_page.keys():\n","            if ('_lvl_' in key):\n","                results[key] = df_page[key]\n","        results = results.rename(columns = {\n","                'itemId' : 'itemId_lvl_{}'.format(current_level),\n","                'value' : 'value_lvl_{}'.format(current_level)\n","        })\n","        return results\n","\n","    def _get_metrics(self):\n","        '''\n","        Return Metric names as Data frame. The index is the same as \n","        the id used during the add_metric function.\n","        '''\n","        # Obtain Metrics Name - start\n","        index = []\n","        metricName = []\n","        for metric in self.report_object['metricContainer']['metrics']:\n","            index.append(metric['columnId'])\n","            metricName.append(metric['id'])\n","        metricNames = pd.DataFrame(index=index, data=metricName)\n","        # metricNames.columns = ['metrics']\n","        # Obtain Metrics Name - end\n","        return metricNames\n","\n","    def format_output(self, data):\n","        '''\n","        Format the API repsonse.\n","\n","        The post request returns a response object. The object is converted into a Pandas data frame.\n","        As metric names, the original values that were provided by the user are used.\n","        \n","        Parameters\n","        ----------\n","        data : response object\n","            Response object as returned from the post request performed.\n","\n","        Returns\n","        -------\n","        Pandas data frame\n","            A data frame that contains returned data including the itemId.\n","        '''\n","\n","        metricNames = self._get_metrics()\n","        data_json = data.json()\n","        # Convert to DF to easily obtain the data column\n","        df_response_data = pd.DataFrame(data_json['rows'])\n","        # Convert metrics to DF into dedicated columns. Column header is the metric ID\n","        if (data_json['totalPages'] > 0) and (df_response_data.shape != (0,0)):\n","            metrics_column = df_response_data.data.tolist()\n","            df_metrics_data = pd.DataFrame(metrics_column, index=df_response_data.index)\n","        else:\n","            \n","            metrics_column = []\n","            \n","            idx = data_json['columns']['columnIds']\n","            for i in idx:\n","                metrics_column.append(0)\n","            df_response_data = pd.DataFrame({'itemId': '0', 'value': 'Unspecified', 'data': metrics_column })\n","            \n","            metrics_column = [metrics_column]\n","            df_metrics_data = pd.DataFrame(metrics_column)\n","            \n","        # Rename metrics' column headers into the metric name, based on the metric ID\n","        df_metrics_data.rename(columns=lambda x: metricNames[metricNames.index == '{}'.format(x)].iloc[0][0], inplace=True)\n","\n","        return pd.merge(df_response_data, df_metrics_data, left_index=True, right_index=True).drop(columns=['data'])\n","\n","    def add_metric(self, metric_name):\n","        metric = self._generate_metric_structure()\n","        existing_number_of_metrics = len(self.report_object['metricContainer']['metrics'])\n","\n","        metric['columnId'] = '{}'.format(existing_number_of_metrics)\n","        metric['id'] = metric_name\n","\n","        self.report_object['metricContainer']['metrics'].append(metric)\n","\n","    def add_dimension(self, dimension_name):\n","        '''\n","        Add a new dimension.\n","\n","        Add an extra dimension that will be used in the final results.\n","        The order dimensions are added affect how results are reported.\n","        \n","        Parameters\n","        ----------\n","        dimension_name : string\n","            Dimension name as expected by the Adobe API.\n","\n","        '''\n","        self.dimensions.append(dimension_name)\n","        if (len(self.report_object['dimension']) == 0):\n","            self.set_dimension(dimension_name)\n","\n","    def set_dimension(self, dimension_name, sort='asc'):\n","        '''\n","        Configure main dimension.\n","\n","        Configure the reporting dimension. Used for single dimension reports.\n","        This will be the top-level break down of the metrics.\n","        The value is added in the JSON report object used in the post request.\n","        \n","        Parameters\n","        ----------\n","        dimension_name : string\n","            Dimension name as expected by the Adobe API.\n","\n","        '''\n","        self.report_object['dimension'] = dimension_name\n","        self._set_report_setting('dimensionSort', sort)\n","\n","    def add_global_segment(self, segment_id = None):\n","        '''\n","        Add a global segment into the report request\n","\n","        A global segment is equivalent of adding a segment in the root of the panel in Adobe Workspace.\n","        \n","        Parameters\n","        ----------\n","\n","        segment_id : string\n","            Unique segment ID\n","        '''\n","        \n","        if segment_id is not None:\n","            segment_filter = {}\n","            segment_filter['type'] = 'segment'\n","            segment_filter['segmentId'] = segment_id\n","            self.report_object['globalFilters'].append(segment_filter)\n","\n","    def set_date_range(self, date_start, date_end, hour_start = 00, hour_end = 24):\n","        '''\n","        Set the start and end date. Optional start/end hour.\n","\n","        The starting date and the ending date for the reporting period is saved into the JSON report object.\n","        The values are first formated in an API-compatible format using _format_date_range function.\n","        The final value is saved in the JSON report object.\n","\n","        Optionally the start hour of the start date and the end hour of the end date can be configured.\n","        - If the hour_start parameter is set greater than 0, then the date range will start from that time slot onwards.\n","        - If the hour_end parameter is not set, then only then the full day will be downloaded.\n","        - If the hour_end parameter is set greater than 0, then only the portion of the last day will be downloaded.\n","        \n","        Parameters\n","        ----------\n","        date_start : string\n","            Reporting period start date. Format: YYYY-MM-DD i.e. 2017-12-31\n","\n","        date_end : string\n","            Reporting period start date. Format: YYYY-MM-DD i.e. 2018-01-31.  \n","\n","        hour_start: int - optional\n","            Reporting period start hour. Integer value from 0 to 24\n","\n","        hour_end: int - optional\n","            Reporting period start hour. Integer value from 0 to 24 \n","        '''\n","\n","        formated_date_range = self._format_date_range(date_start=date_start, date_end=date_end, hour_start = hour_start, hour_end= hour_end)\n","        date_range_globabl_filter =  {\n","            \"type\": \"dateRange\",\n","            \"dateRange\": formated_date_range\n","        }\n","        self.report_object['globalFilters'].append(date_range_globabl_filter)\n","        # self.report_object['globalFilters'][0]['dateRange'] = formated_date_range\n","\n","    def set_limit(self, rows_limit):\n","        self._set_report_setting('limit', rows_limit)\n","\n","    def _set_page_number(self, page_no):\n","        self._set_report_setting('page', page_no)\n","\n","    def _set_report_setting(self, setting_item, value):\n","        self.report_object = self._add_key_to_dict(\n","            self.report_object, 'settings')\n","        self.report_object['settings'] = self._add_key_to_dict(\n","            self.report_object['settings'], setting_item)\n","        self.report_object['settings'][setting_item] = '{}'.format(value)\n","\n","    def clean_report_object(self):\n","        self.report_object = self._generate_empty_report_object()\n","\n","    @staticmethod\n","    def _add_key_to_dict(dict_obj, key):\n","        if (key not in dict_obj):\n","            dict_obj[key] = {}\n","        return dict_obj\n","\n","    @staticmethod\n","    def _add_breakdown_report_object(report_object, breakdown, item_id):\n","        '''\n","        When multiple breakdowns are added in a report, the JSON report object needs to be updated in each POST request.\n","        Everytime the metricFilters and the main dimension are updated dynamically based on the itemId's\n","        '''\n","        report_object = json.loads(json.dumps(report_object))\n","        original_breakdown = report_object['dimension']\n","        if ('metricFilters' in report_object['metricContainer']):\n","            metrics_filter_num = len(report_object['metricContainer']['metricFilters'])\n","        else:\n","            metrics_filter_num = 0\n","            report_object['metricContainer']['metricFilters'] = []\n","        \n","        for metric in report_object['metricContainer']['metrics']:\n","            metric_filter = {}\n","            metric_filter['id'] = '{}'.format(metrics_filter_num)\n","            metric_filter['type'] = 'breakdown'\n","            metric_filter['dimension'] = original_breakdown\n","            metric_filter['itemId'] = '{}'.format(item_id)\n","            metrics_filter_num = metrics_filter_num + 1\n","            \n","            report_object['metricContainer']['metricFilters'].append(metric_filter)\n","            \n","            if 'filters' not in metric:\n","                metric['filters'] = []\n","            \n","            metric['filters'].append(metric_filter['id'])\n","        \n","        report_object['dimension'] = breakdown\n","        return report_object\n","\n","    def logger(self, message):\n","        if (self.debugging):\n","            print('Analytics Debugger Start')\n","            print(message)\n","            print('Analytics Debugger End')\n","\n","    def write_log(self, filename, message):\n","        \n","        if (not os.path.exists('logs')):\n","            os.mkdir('logs')\n","\n","        fil = open(\"logs/{}-{}.json\".format(filename,datetime.now().isoformat()), \"a\")  # append mode \n","        fil.write(message) \n","        fil.close() "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1151b09f-d207-4729-971a-dab18dc42282","showTitle":false,"title":""}},"outputs":[],"source":["aa = analytics_client(\n","        adobe_org_id = ADOBE_ORG_ID, \n","        subject_account = SUBJECT_ACCOUNT, \n","        client_id = CLIENT_ID, \n","        client_secret = CLIENT_SECRET,\n","        account_id = GLOBAL_COMPANY_ID\n",")\n","\n","aa.set_report_suite(report_suite_id = REPORT_SUITE_ID)\n","\n","#get start date and end date based on current eastern standard time\n","date_start = datetime.now(timezone('EST')).date().replace(day=1).strftime('%Y-%m-%d')\n","date_end= datetime.now(timezone('EST')).strftime('%Y-%m-%d')\n","\n","aa.set_date_range(date_start, date_end)\n","\n","\n","#add segments\n","for segment in re.split(', |,', segments):\n","    aa.add_global_segment(segment_id = segment)\n","\n","#add metrics\n","for metric in re.split(', |,', metrics):\n","    aa.add_metric(metric_name = metric)\n","\n","#add dimensions\n","for dimension in re.split(', |,', dimensions):\n","    aa.add_dimension(dimension_name = dimension)\n","\n","\n","\n","data = aa.get_report_multiple_breakdowns()\n","\n","print(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"10e5f48a-043d-4495-afa8-bb2e153fb382","showTitle":false,"title":""}},"outputs":[],"source":["#connect to adls \n","account_name = \"stsaebdevca01\"\n","container_name = \"adobeanalytics\"\n","\n","#get adls key from secret scope bcked by azure key vault\n","account_key = dbutils.secrets.get(scope = \"akv-saeb-dbc-scrt-scp\", key = \"saebadlsstorageaccesskey\")\n","\n","connection_string = 'DefaultEndpointsProtocol=https;AccountName=' + account_name + ';AccountKey=' + account_key\n","blob_name = output_file_path\n","\n","#upload data in blob\n","blob = BlobClient.from_connection_string(conn_str=connection_string, container_name=container_name, blob_name=blob_name)\n","blob.upload_blob(data.to_csv(), overwrite=True)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"AA Ingestion Script","notebookOrigID":3213229525829659,"widgets":{"dimensions":{"currentValue":"","nuid":"858740b7-2454-4c6c-979a-25b9c9a98d58","widgetInfo":{"defaultValue":"","label":"","name":"dimensions","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}},"metrics":{"currentValue":"","nuid":"7395672d-fb33-4328-a4e0-4f05d9e1043f","widgetInfo":{"defaultValue":"","label":"","name":"metrics","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}},"output_file_path":{"currentValue":"","nuid":"bdb21acd-421c-4ecc-91f9-359edf37a1ab","widgetInfo":{"defaultValue":"","label":"","name":"output_file_path","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}},"segments":{"currentValue":"","nuid":"e440cb11-abb1-427d-a033-32f260b45862","widgetInfo":{"defaultValue":"","label":"","name":"segments","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}}}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
